# compressor_system.py - ê²½ëŸ‰ AIê°€ í†µí•©ëœ ì••ì¶•ê¸° ì§„ë‹¨ ì‹œìŠ¤í…œ
import streamlit as st
import librosa
import numpy as np
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import sqlite3
import json
import io
from datetime import datetime, timedelta
import time
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from scipy import signal
import pickle
import os
import warnings
warnings.filterwarnings('ignore')

# ê²½ëŸ‰ AI ëª¨ë¸ í´ë˜ìŠ¤ (í†µí•©)
class LightweightCompressorAI:
    """ë…¸íŠ¸ë¶ í™˜ê²½ì— ìµœì í™”ëœ ê²½ëŸ‰ ì••ì¶•ê¸° ì§„ë‹¨ AI"""
    
    def __init__(self):
        self.model_type = "hybrid"
        self.is_trained = False
        self.model_path = "models/lightweight_compressor_ai.pkl"
        
        # ì••ì¶•ê¸° ë¼ë²¨
        self.labels = {
            'compressor_normal': 'ì •ìƒ ì••ì¶•ê¸°',
            'compressor_overload': 'ì••ì¶•ê¸° ê³¼ë¶€í•˜', 
            'compressor_bearing_wear': 'ì••ì¶•ê¸° ë² ì–´ë§ ë§ˆëª¨',
            'compressor_valve_fault': 'ì••ì¶•ê¸° ë°¸ë¸Œ ì´ìƒ',
            'fan_normal': 'ì •ìƒ íŒ¬ ë™ì‘',
            'fan_imbalance': 'íŒ¬ ë¶ˆê· í˜•',
            'fan_bearing_wear': 'íŒ¬ ë² ì–´ë§ ë§ˆëª¨',
            'refrigerant_normal': 'ì •ìƒ ëƒ‰ë§¤ íë¦„',
            'refrigerant_low': 'ëƒ‰ë§¤ ë¶€ì¡±',
            'refrigerant_leak': 'ëƒ‰ë§¤ ëˆ„ì¶œ',
            'vibration_mount': 'ë§ˆìš´íŠ¸ ì§„ë™',
            'electrical_noise': 'ì „ê¸° ë…¸ì´ì¦ˆ'
        }
        
        self.label_to_idx = {label: idx for idx, label in enumerate(self.labels.keys())}
        self.idx_to_label = {idx: label for label, idx in self.label_to_idx.items()}
        
        # ëª¨ë¸ ì»´í¬ë„ŒíŠ¸
        self.scaler = StandardScaler()
        self.rf_model = RandomForestClassifier(
            n_estimators=30,  # ê°€ë²¼ìš´ ì„¤ì •
            max_depth=8,
            random_state=42,
            n_jobs=2  # CPU ì½”ì–´ ì œí•œ
        )
        
        # ê¸°ì¡´ ëª¨ë¸ ë¡œë“œ ì‹œë„
        self.load_model()
    
    def extract_lightweight_features(self, audio, sr=16000):
        """ê²½ëŸ‰í™”ëœ íŠ¹ì§• ì¶”ì¶œ"""
        features = []
        
        # ì˜¤ë””ì˜¤ ê¸¸ì´ ì œí•œ (1ì´ˆ)
        if len(audio) > sr:
            audio = audio[:sr]
        elif len(audio) < sr:
            audio = np.pad(audio, (0, sr - len(audio)))
        
        # 1. ê¸°ë³¸ í†µê³„ íŠ¹ì§•
        features.extend([
            np.mean(audio),
            np.std(audio),
            np.max(audio),
            np.min(audio),
            np.median(audio)
        ])
        
        # 2. ì£¼íŒŒìˆ˜ íŠ¹ì§•
        try:
            fft = np.fft.fft(audio)
            freqs = np.fft.fftfreq(len(audio), 1/sr)
            
            positive_mask = freqs > 0
            freqs = freqs[positive_mask]
            magnitude = np.abs(fft[positive_mask])
            
            # ì£¼íŒŒìˆ˜ ëŒ€ì—­ë³„ ì—ë„ˆì§€
            bands = [(10, 100), (100, 500), (500, 1500), (1500, 3000), (3000, 8000)]
            total_energy = np.sum(magnitude)
            
            for low, high in bands:
                band_mask = (freqs >= low) & (freqs <= high)
                if np.any(band_mask) and total_energy > 0:
                    band_energy = np.sum(magnitude[band_mask])
                    features.append(band_energy / total_energy)
                else:
                    features.append(0)
                    
        except Exception:
            features.extend([0] * 5)
        
        # 3. ì‹œê°„ ë„ë©”ì¸ íŠ¹ì§•
        try:
            rms = np.sqrt(np.mean(audio**2))
            features.append(rms)
            
            peak = np.max(np.abs(audio))
            crest_factor = peak / rms if rms > 0 else 0
            features.append(crest_factor)
            
        except Exception:
            features.extend([0] * 2)
        
        return np.array(features, dtype=np.float32)
    
    def predict(self, audio, sr=16000):
        """ì˜ˆì¸¡ ìˆ˜í–‰"""
        if not self.is_trained:
            return self._generate_mock_prediction()
        
        try:
            features = self.extract_lightweight_features(audio, sr)
            features = features.reshape(1, -1)
            
            features_scaled = self.scaler.transform(features)
            
            if hasattr(self.rf_model, 'predict_proba'):
                rf_prob = self.rf_model.predict_proba(features_scaled)[0]
                rf_pred = np.argmax(rf_prob)
                confidence = rf_prob[rf_pred]
            else:
                rf_pred = self.rf_model.predict(features_scaled)[0]
                confidence = 0.75
            
            predicted_label = self.idx_to_label[rf_pred]
            return predicted_label, float(confidence)
            
        except Exception as e:
            print(f"ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
            return self._generate_mock_prediction()
    
    def _generate_mock_prediction(self):
        """ì‹œì—°ìš© ê°€ì§œ ì˜ˆì¸¡"""
        mock_cases = [
            ('compressor_normal', 0.85),
            ('compressor_overload', 0.78),
            ('fan_imbalance', 0.73),
            ('refrigerant_low', 0.82),
            ('vibration_mount', 0.76)
        ]
        
        weights = [0.4, 0.2, 0.15, 0.15, 0.1]
        choice = np.random.choice(len(mock_cases), p=weights)
        return mock_cases[choice]
    
    def train_with_data(self, audio_files, labels):
        """ëª¨ë¸ í•™ìŠµ"""
        try:
            features_list = []
            labels_list = []
            
            for audio_file, label in zip(audio_files, labels):
                if isinstance(audio_file, str):
                    audio, sr = librosa.load(audio_file, sr=16000, mono=True)
                else:
                    audio, sr = audio_file, 16000
                
                features = self.extract_lightweight_features(audio, sr)
                features_list.append(features)
                
                label_idx = self.label_to_idx.get(label, 0)
                labels_list.append(label_idx)
            
            if len(features_list) < 5:
                return False
            
            X = np.array(features_list)
            y = np.array(labels_list)
            
            # ì •ê·œí™”
            X_scaled = self.scaler.fit_transform(X)
            
            # í•™ìŠµ
            self.rf_model.fit(X_scaled, y)
            self.save_model()
            self.is_trained = True
            
            return True
            
        except Exception as e:
            print(f"í•™ìŠµ ì˜¤ë¥˜: {e}")
            return False
    
    def save_model(self):
        """ëª¨ë¸ ì €ì¥"""
        try:
            os.makedirs("models", exist_ok=True)
            
            model_data = {
                'scaler': self.scaler,
                'rf_model': self.rf_model,
                'labels': self.labels,
                'label_to_idx': self.label_to_idx,
                'idx_to_label': self.idx_to_label,
                'is_trained': self.is_trained
            }
            
            with open(self.model_path, 'wb') as f:
                pickle.dump(model_data, f)
                
        except Exception as e:
            print(f"ëª¨ë¸ ì €ì¥ ì˜¤ë¥˜: {e}")
    
    def load_model(self):
        """ëª¨ë¸ ë¡œë“œ"""
        try:
            if os.path.exists(self.model_path):
                with open(self.model_path, 'rb') as f:
                    model_data = pickle.load(f)
                
                self.scaler = model_data['scaler']
                self.rf_model = model_data['rf_model']
                self.is_trained = model_data.get('is_trained', False)
                return True
        except Exception:
            return False
    
    def get_model_info(self):
        """ëª¨ë¸ ì •ë³´"""
        return {
            'name': 'ê²½ëŸ‰ ì••ì¶•ê¸° AI',
            'type': 'RandomForest',
            'status': 'í•™ìŠµë¨' if self.is_trained else 'ë¯¸í•™ìŠµ',
            'memory_usage': '~30MB',
            'speed': 'ë§¤ìš° ë¹ ë¦„',
            'accuracy': '75-85%',
            'features': 12
        }

# AI ëª¨ë¸ ë§¤ë‹ˆì €
class AIModelManager:
    def __init__(self):
        self.lightweight_ai = LightweightCompressorAI()
        self.active_model = self.lightweight_ai
    
    def predict(self, audio, sr=16000):
        return self.active_model.predict(audio, sr)
    
    def train_model(self, audio_files, labels):
        return self.lightweight_ai.train_with_data(audio_files, labels)
    
    def get_model_info(self):
        return {'lightweight': self.lightweight_ai.get_model_info()}

class CompressorDiagnosisSystem:
    def __init__(self):
        self.init_database()
        self.init_models()
        
        # ê²½ëŸ‰ AI ë§¤ë‹ˆì € ì¶”ê°€
        try:
            self.ai_manager = AIModelManager()
            self.ai_enabled = True
            print("âœ… ê²½ëŸ‰ AI ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
        except Exception as e:
            print(f"âš ï¸ AI ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.ai_enabled = False
        
        # ì••ì¶•ê¸° ë¼ë²¨
        self.labels = {
            'compressor_normal': 'ì •ìƒ ì••ì¶•ê¸°',
            'compressor_overload': 'ì••ì¶•ê¸° ê³¼ë¶€í•˜',
            'compressor_bearing_wear': 'ì••ì¶•ê¸° ë² ì–´ë§ ë§ˆëª¨',
            'compressor_valve_fault': 'ì••ì¶•ê¸° ë°¸ë¸Œ ì´ìƒ',
            'fan_normal': 'ì •ìƒ íŒ¬ ë™ì‘',
            'fan_imbalance': 'íŒ¬ ë¶ˆê· í˜•',
            'fan_bearing_wear': 'íŒ¬ ë² ì–´ë§ ë§ˆëª¨',
            'refrigerant_normal': 'ì •ìƒ ëƒ‰ë§¤ íë¦„',
            'refrigerant_low': 'ëƒ‰ë§¤ ë¶€ì¡±',
            'refrigerant_leak': 'ëƒ‰ë§¤ ëˆ„ì¶œ',
            'vibration_mount': 'ë§ˆìš´íŠ¸ ì§„ë™',
            'electrical_noise': 'ì „ê¸° ë…¸ì´ì¦ˆ'
        }
        
        # ì£¼íŒŒìˆ˜ ëŒ€ì—­
        self.frequency_bands = {
            'low_freq': {'name': 'ì €ì£¼íŒŒ (10-100Hz)', 'range': (10, 100), 'color': '#4ECDC4'},
            'compressor_freq': {'name': 'ì••ì¶•ê¸° (100-500Hz)', 'range': (100, 500), 'color': '#45B7D1'},
            'motor_freq': {'name': 'ëª¨í„° (500-1500Hz)', 'range': (500, 1500), 'color': '#96CEB4'},
            'fan_freq': {'name': 'íŒ¬ (1.5-3kHz)', 'range': (1500, 3000), 'color': '#FFEAA7'},
            'refrigerant_freq': {'name': 'ëƒ‰ë§¤ (3-8kHz)', 'range': (3000, 8000), 'color': '#DDA0DD'},
            'high_freq': {'name': 'ê³ ì£¼íŒŒ (8kHz+)', 'range': (8000, 20000), 'color': '#FF9999'}
        }

    def init_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        self.conn = sqlite3.connect('compressor_system.db', check_same_thread=False)
        
        # íŒŒì¼ í…Œì´ë¸”
        self.conn.execute('''
            CREATE TABLE IF NOT EXISTS audio_files (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                filename TEXT UNIQUE NOT NULL,
                upload_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                duration REAL,
                sample_rate INTEGER,
                file_path TEXT,
                customer_id TEXT,
                equipment_id TEXT
            )
        ''')
        
        # ë¼ë²¨ í…Œì´ë¸”
        self.conn.execute('''
            CREATE TABLE IF NOT EXISTS labels (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                file_id INTEGER,
                start_time REAL,
                end_time REAL,
                label_type TEXT,
                confidence INTEGER,
                notes TEXT,
                created_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (file_id) REFERENCES audio_files (id)
            )
        ''')
        
        # ì˜ˆì¸¡ í…Œì´ë¸”
        self.conn.execute('''
            CREATE TABLE IF NOT EXISTS predictions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                file_id INTEGER,
                predicted_label TEXT,
                confidence_score REAL,
                prediction_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (file_id) REFERENCES audio_files (id)
            )
        ''')
        
        # ê³ ê° í…Œì´ë¸”
        self.conn.execute('''
            CREATE TABLE IF NOT EXISTS customers (
                id TEXT PRIMARY KEY,
                company_name TEXT,
                contact_person TEXT,
                email TEXT,
                phone TEXT,
                created_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        self.conn.commit()

    def init_models(self):
        """ëª¨ë¸ ì´ˆê¸°í™”"""
        self.scaler = StandardScaler()
        self.label_encoder = LabelEncoder()
        
        self.algorithms = {
            'RandomForest': RandomForestClassifier(n_estimators=50, random_state=42),
            'GradientBoosting': GradientBoostingClassifier(n_estimators=50, random_state=42),
            'SVM': SVC(probability=True, random_state=42)
        }

    def create_ui(self):
    """ë©”ì¸ UI ìƒì„± (ë§¤ë‰´ì–¼ ë° ì—°ë½ì²˜ í†µí•©)"""
    st.set_page_config(
        page_title="ì••ì¶•ê¸° AI ì§„ë‹¨ ì‹œìŠ¤í…œ",
        page_icon="ğŸ­",
        layout="wide"
    )
    
    # í—¤ë” (ë²„ì „ ì •ë³´ ì¶”ê°€)
    ai_badge = "ğŸ¤– AI í™œì„±" if self.ai_enabled else "âšª AI ë¹„í™œì„±"
    st.markdown(f"""
    <div style="background: linear-gradient(90deg, #667eea 0%, #764ba2 100%); 
                padding: 2rem; border-radius: 15px; color: white; text-align: center; margin-bottom: 2rem;">
        <h1>ğŸ­ ì••ì¶•ê¸° AI ì§„ë‹¨ ì‹œìŠ¤í…œ</h1>
        <h3>ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ ì‹¤ì‹œê°„ ì§„ë‹¨ ì†”ë£¨ì…˜</h3>
        <p style="margin: 0; opacity: 0.8;">{ai_badge} | v1.0.0 | ë…¸íŠ¸ë¶ ìµœì í™”</p>
        <p style="margin: 0; opacity: 0.7; font-size: 0.9em;">
            ğŸ’¡ ì²˜ìŒ ì‚¬ìš©í•˜ì‹œë‚˜ìš”? 'ğŸ“– ì‚¬ìš©ë²•' íƒ­ì„ ë¨¼ì € í™•ì¸í•´ë³´ì„¸ìš”!
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # ì‚¬ì´ë“œë°” (ì—…ë°ì´íŠ¸ëœ ì •ë³´)
    with st.sidebar:
        st.header("ğŸ›ï¸ ì‹œìŠ¤í…œ ìƒíƒœ")
        
        stats = self.get_system_stats()
        st.markdown(f"""
        **ğŸ“Š ì‹œìŠ¤í…œ í†µê³„**
        - ì´ íŒŒì¼: {stats['total_files']}ê°œ
        - ë¼ë²¨ ë°ì´í„°: {stats['total_labels']}ê°œ
        - AI ì˜ˆì¸¡: {stats['total_predictions']}ê°œ
        - ê³ ê° ìˆ˜: {stats['total_customers']}ê°œ
        """)
        
        # AI ëª¨ë¸ ìƒíƒœ
        st.header("ğŸ¤– AI ëª¨ë¸ ìƒíƒœ")
        if self.ai_enabled:
            model_info = self.ai_manager.get_model_info()['lightweight']
            
            st.success("âœ… ê²½ëŸ‰ AI í™œì„±")
            st.markdown(f"""
            **ëª¨ë¸ ì •ë³´:**
            - ìƒíƒœ: {model_info['status']}
            - ì •í™•ë„: {model_info['accuracy']}
            - ì†ë„: {model_info['speed']}
            """)
        else:
            st.error("âŒ AI ëª¨ë¸ ë¹„í™œì„±")
        
        # ë¹ ë¥¸ ë§í¬
        st.header("ğŸ”— ë¹ ë¥¸ ë§í¬")
        st.markdown("""
        - ğŸ“– [ì‚¬ìš©ë²• ê°€ì´ë“œ](#ì‚¬ìš©ë²•)
        - ğŸ“ [ì—°ë½ì²˜ & í›„ì›](#ì—°ë½ì²˜)
        - ğŸ› [ë²„ê·¸ ì‹ ê³ ](https://github.com/username/compressor-ai-diagnosis/issues)
        - ğŸ’¡ [ê¸°ëŠ¥ ì œì•ˆ](https://github.com/username/compressor-ai-diagnosis/discussions)
        """)
    
    # ë©”ì¸ íƒ­ (ìƒˆ íƒ­ë“¤ ì¶”ê°€)
    tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
        "ğŸ“ íŒŒì¼ ê´€ë¦¬", 
        "ğŸ”¬ ë¶„ì„", 
        "ğŸ¤– AI í•™ìŠµ",
        "ğŸ“Š ëŒ€ì‹œë³´ë“œ",
        "ğŸ“– ì‚¬ìš©ë²•",
        "ğŸ“ ì—°ë½ì²˜ & í›„ì›",
        "âš™ï¸ ì„¤ì •"
    ])
    
    with tab1:
        self.file_management_tab()
    
    with tab2:
        self.analysis_tab()
        
    with tab3:
        self.ai_learning_tab()
        
    with tab4:
        self.dashboard_tab()
        
    with tab5:
        self.user_manual_tab()  # ìƒˆë¡œ ì¶”ê°€
        
    with tab6:
        self.contact_support_tab()  # ìƒˆë¡œ ì¶”ê°€
        
    with tab7:
        self.settings_tab()

    def file_management_tab(self):
        """íŒŒì¼ ê´€ë¦¬ íƒ­"""
        st.header("ğŸ“ íŒŒì¼ ê´€ë¦¬")
        
        # ê³ ê° ì •ë³´ ì…ë ¥
        with st.expander("ğŸ‘¤ ê³ ê° ì •ë³´", expanded=True):
            col1, col2 = st.columns(2)
            
            with col1:
                customer_id = st.text_input("ê³ ê° ID", placeholder="CUST_001")
                company_name = st.text_input("íšŒì‚¬ëª…", placeholder="â—‹â—‹ëƒ‰ë™")
                contact_person = st.text_input("ë‹´ë‹¹ì", placeholder="í™ê¸¸ë™")
            
            with col2:
                email = st.text_input("ì´ë©”ì¼", placeholder="contact@company.com")
                phone = st.text_input("ì—°ë½ì²˜", placeholder="02-1234-5678")
                equipment_id = st.text_input("ì¥ë¹„ ID", placeholder="COMP_001")
        
        # íŒŒì¼ ì—…ë¡œë“œ
        st.subheader("ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ")
        
        uploaded_files = st.file_uploader(
            "ì••ì¶•ê¸° ì†Œë¦¬ íŒŒì¼ ì—…ë¡œë“œ",
            type=['wav', 'mp3'],
            accept_multiple_files=True
        )
        
        if uploaded_files:
            # ì—…ë¡œë“œ ì˜µì…˜
            col1, col2, col3 = st.columns(3)
            
            with col1:
                auto_analysis = st.checkbox("ìë™ ë¶„ì„", value=True)
            with col2:
                auto_prediction = st.checkbox("AI ì˜ˆì¸¡", value=True)
            with col3:
                batch_labeling = st.checkbox("ë°°ì¹˜ ë¼ë²¨ë§", value=False)
            
            # ì²˜ë¦¬ ì‹¤í–‰
            if st.button("ğŸš€ íŒŒì¼ ì²˜ë¦¬", type="primary"):
                if customer_id and company_name:
                    self.save_customer_info(customer_id, company_name, contact_person, email, phone)
                
                results = self.process_files(
                    uploaded_files, customer_id, equipment_id, 
                    auto_analysis, auto_prediction, batch_labeling
                )
                
                st.success(f"âœ… {len(uploaded_files)}ê°œ íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ!")
                st.dataframe(pd.DataFrame(results))
        
        # íŒŒì¼ ëª©ë¡
        st.subheader("ğŸ“‹ ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡")
        
        files_df = self.get_files_list()
        if not files_df.empty:
            st.dataframe(files_df, use_container_width=True)

    def analysis_tab(self):
        """ë¶„ì„ íƒ­"""
        st.header("ğŸ”¬ ì••ì¶•ê¸° ë¶„ì„")
        
        # íŒŒì¼ ì„ íƒ
        files_df = self.get_files_list()
        
        if files_df.empty:
            st.warning("ë¶„ì„í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
            return
        
        selected_file_id = st.selectbox(
            "ë¶„ì„í•  íŒŒì¼ ì„ íƒ",
            options=files_df.index,
            format_func=lambda x: f"{files_df.loc[x, 'filename']} ({files_df.loc[x, 'upload_time']})"
        )
        
        if selected_file_id is not None:
            file_info = files_df.loc[selected_file_id]
            
            # íŒŒì¼ ì •ë³´
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("íŒŒì¼ëª…", file_info['filename'])
            with col2:
                st.metric("ê¸¸ì´", f"{file_info.get('duration', 0):.2f}ì´ˆ")
            with col3:
                st.metric("ìƒ˜í”Œë§ ë ˆì´íŠ¸", f"{file_info.get('sample_rate', 0)} Hz")
            
            # ë¶„ì„ ì‹¤í–‰
            col1, col2 = st.columns(2)
            
            with col1:
                if st.button("ğŸ” ê¸°ë³¸ ë¶„ì„", type="secondary"):
                    self.run_basic_analysis(file_info)
            
            with col2:
                if st.button("ğŸ¤– AI ë¶„ì„", type="primary"):
                    self.run_ai_analysis(file_info)

    def run_basic_analysis(self, file_info):
        """ê¸°ë³¸ ë¶„ì„ ì‹¤í–‰"""
        try:
            with st.spinner("ë¶„ì„ ì¤‘..."):
                audio_path = file_info.get('file_path', f"uploads/{file_info['filename']}")
                audio, sr = librosa.load(audio_path, sr=None, mono=True)
                
                analysis_result = self.perform_basic_analysis(audio, sr)
                self.display_basic_results(analysis_result)
                
        except Exception as e:
            st.error(f"ë¶„ì„ ì˜¤ë¥˜: {e}")

    def run_ai_analysis(self, file_info):
        """AI ë¶„ì„ ì‹¤í–‰"""
        if not self.ai_enabled:
            st.error("âŒ AI ëª¨ë¸ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            return
        
        try:
            with st.spinner("ğŸ¤– AI ë¶„ì„ ì¤‘..."):
                audio_path = file_info.get('file_path', f"uploads/{file_info['filename']}")
                audio, sr = librosa.load(audio_path, sr=None, mono=True)
                
                ai_result = self.predict_with_ai(audio, sr, file_info['id'])
                basic_result = self.perform_basic_analysis(audio, sr)
                
                # ê²°ê³¼ í‘œì‹œ
                col1, col2 = st.columns([1, 1])
                
                with col1:
                    st.markdown(f"""
                    <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                                padding: 1.5rem; border-radius: 10px; color: white; margin: 1rem 0;">
                        <h3>ğŸ¤– AI ì§„ë‹¨ ê²°ê³¼</h3>
                        <h2 style="margin: 0.5rem 0;">{ai_result}</h2>
                        <p style="margin: 0; opacity: 0.9;">ê²½ëŸ‰ AI ëª¨ë¸ ê¸°ë°˜</p>
                    </div>
                    """, unsafe_allow_html=True)
                
                with col2:
                    model_info = self.ai_manager.get_model_info()['lightweight']
                    st.info(f"""
                    **ì‚¬ìš©ëœ AI ëª¨ë¸:**
                    - {model_info['name']}
                    - ì²˜ë¦¬ì‹œê°„: {model_info['speed']}
                    - íŠ¹ì§• ê°œìˆ˜: {model_info['features']}ê°œ
                    """)
                
                self.display_basic_results(basic_result)
                
        except Exception as e:
            st.error(f"âŒ AI ë¶„ì„ ì˜¤ë¥˜: {e}")

    def predict_with_ai(self, audio, sr, file_id):
        """AI ì˜ˆì¸¡"""
        if not self.ai_enabled:
            return "AI ëª¨ë¸ ë¹„í™œì„± - ìˆ˜ë™ ë¶„ì„ í•„ìš”"
        
        try:
            predicted_label, confidence = self.ai_manager.predict(audio, sr)
            
            # ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
            self.conn.execute('''
                INSERT INTO predictions 
                (file_id, predicted_label, confidence_score)
                VALUES (?, ?, ?)
            ''', (file_id, predicted_label, confidence))
            
            self.conn.commit()
            
            korean_label = self.labels.get(predicted_label, predicted_label)
            
            if confidence >= 0.8:
                confidence_color = "ğŸŸ¢"
            elif confidence >= 0.6:
                confidence_color = "ğŸŸ¡" 
            else:
                confidence_color = "ğŸ”´"
            
            return f"{confidence_color} {korean_label} (ì‹ ë¢°ë„: {confidence:.1%})"
            
        except Exception as e:
            return f"âŒ AI ì˜ˆì¸¡ ì˜¤ë¥˜: {e}"

    def perform_basic_analysis(self, audio, sr):
        """ê¸°ë³¸ ë¶„ì„ ìˆ˜í–‰"""
        # ì£¼íŒŒìˆ˜ ë¶„ì„
        fft_result = np.fft.fft(audio)
        frequencies = np.fft.fftfreq(len(audio), 1/sr)
        power_spectrum = np.abs(fft_result) ** 2
        
        positive_mask = frequencies > 0
        frequencies = frequencies[positive_mask]
        power_spectrum = power_spectrum[positive_mask]
        
        # ì£¼íŒŒìˆ˜ ëŒ€ì—­ë³„ ì—ë„ˆì§€
        band_energies = {}
        total_energy = np.sum(power_spectrum)
        
        for band_name, band_info in self.frequency_bands.items():
            freq_min, freq_max = band_info['range']
            band_mask = (frequencies >= freq_min) & (frequencies <= freq_max)
            
            if np.any(band_mask):
                band_energy = np.sum(power_spectrum[band_mask])
                band_energies[band_name] = {
                    'energy_ratio': band_energy / total_energy,
                    'dominant_freq': frequencies[band_mask][np.argmax(power_spectrum[band_mask])]
                }
        
        # ì§„ë™ ë¶„ì„
        rms = np.sqrt(np.mean(audio**2))
        peak = np.max(np.abs(audio))
        crest_factor = peak / rms if rms > 0 else 0
        
        return {
            'frequencies': frequencies,
            'power_spectrum': power_spectrum,
            'band_energies': band_energies,
            'vibration': {
                'rms': rms,
                'peak': peak,
                'crest_factor': crest_factor
            }
        }

    def display_basic_results(self, results):
        """ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
        st.subheader("ğŸ“Š ì£¼íŒŒìˆ˜ ëŒ€ì—­ë³„ ì—ë„ˆì§€")
        
        band_energies = results['band_energies']
        
        if band_energies:
            band_names = []
            band_ratios = []
            band_colors = []
            
            for band_name, data in band_energies.items():
                band_info = self.frequency_bands[band_name]
                band_names.append(band_info['name'])
                band_ratios.append(data['energy_ratio'] * 100)
                band_colors.append(band_info['color'])
            
            fig = go.Figure(data=[
                go.Bar(
                    x=band_names,
                    y=band_ratios,
                    marker_color=band_colors,
                    text=[f"{ratio:.1f}%" for ratio in band_ratios],
                    textposition='auto'
                )
            ])
            
            fig.update_layout(
                title="ì£¼íŒŒìˆ˜ ëŒ€ì—­ë³„ ì—ë„ˆì§€ ë¶„í¬",
                xaxis_title="ì£¼íŒŒìˆ˜ ëŒ€ì—­",
                yaxis_title="ì—ë„ˆì§€ ë¹„ìœ¨ (%)",
                height=400
            )
            
            st.plotly_chart(fig, use_container_width=True)
        
        # ì§„ë™ ë¶„ì„
        st.subheader("ğŸ“³ ì§„ë™ ë¶„ì„")
        
        vibration = results['vibration']
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("RMS", f"{vibration['rms']:.4f}")
        with col2:
            st.metric("í”¼í¬", f"{vibration['peak']:.4f}")
        with col3:
            st.metric("í¬ë ˆìŠ¤íŠ¸ íŒ©í„°", f"{vibration['crest_factor']:.2f}")

    def ai_learning_tab(self):
        """AI í•™ìŠµ íƒ­"""
        st.header("ğŸ¤– AI í•™ìŠµ ì„¼í„°")
        
        if not self.ai_enabled:
            st.error("âŒ AI ëª¨ë¸ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            st.info("ğŸ’¡ ì‹œìŠ¤í…œì„ ë‹¤ì‹œ ì‹œì‘í•´ì£¼ì„¸ìš”.")
            return
        
        # í˜„ì¬ ëª¨ë¸ ìƒíƒœ
        model_info = self.ai_manager.get_model_info()['lightweight']
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ëª¨ë¸ ìƒíƒœ", model_info['status'])
        with col2:
            st.metric("ëª¨ë¸ íƒ€ì…", model_info['type'])
        with col3:
            st.metric("ì²˜ë¦¬ ì†ë„", model_info['speed'])
        with col4:
            st.metric("ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰", model_info['memory_usage'])
        
        # ë°ì´í„°ì…‹ í˜„í™©
        dataset_stats = self.get_dataset_stats()
        
        st.subheader("ğŸ“Š í•™ìŠµ ë°ì´í„° í˜„í™©")
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ì´ ë¼ë²¨", dataset_stats['total_labels'])
        with col2:
            st.metric("í´ë˜ìŠ¤ ìˆ˜", dataset_stats['unique_classes'])
        with col3:
            st.metric("ë°ì´í„° ê· í˜•ë„", f"{dataset_stats['balance_ratio']:.2f}")
        
        # í•™ìŠµ ì„¹ì…˜
        st.subheader("ğŸš€ ê²½ëŸ‰ AI ëª¨ë¸ í•™ìŠµ")
        
        # í•™ìŠµ ì˜µì…˜
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**í•™ìŠµ ì„¤ì •**")
            validation_split = st.slider("ê²€ì¦ ë°ì´í„° ë¹„ìœ¨", 0.1, 0.4, 0.2)
            use_mock_data = st.checkbox("ì‹œì—°ìš© ë”ë¯¸ ë°ì´í„° ì‚¬ìš©", value=True)
            
        with col2:
            st.markdown("**ëª¨ë¸ ì„¤ì •**")
            quick_training = st.checkbox("ë¹ ë¥¸ í•™ìŠµ", value=True, help="ë…¸íŠ¸ë¶ í™˜ê²½ì— ìµœì í™”")
        
        # í•™ìŠµ ì‹¤í–‰
        if st.button("ğŸ¯ AI ëª¨ë¸ í•™ìŠµ ì‹œì‘", type="primary"):
            if use_mock_data:
                st.info("ğŸ§ª ì‹œì—°ìš© ë”ë¯¸ ë°ì´í„°ë¡œ í•™ìŠµí•©ë‹ˆë‹¤...")
                
                with st.spinner("í•™ìŠµ ì¤‘... (ì‹œì—° ëª¨ë“œ)"):
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    status_text.text("ë”ë¯¸ ë°ì´í„° ìƒì„± ì¤‘...")
                    progress_bar.progress(20)
                    
                    dummy_audio_files = [np.random.randn(16000) for _ in range(30)]
                    dummy_labels = (['compressor_normal'] * 15 + 
                                  ['compressor_overload'] * 8 + 
                                  ['fan_imbalance'] * 7)
                    
                    status_text.text("AI ëª¨ë¸ í•™ìŠµ ì¤‘...")
                    progress_bar.progress(50)
                    
                    success = self.ai_manager.train_model(dummy_audio_files, dummy_labels)
                    
                    progress_bar.progress(100)
                    status_text.text("í•™ìŠµ ì™„ë£Œ!")
                    
                    if success:
                        st.success("âœ… AI ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
                        st.balloons()
                        
                        st.markdown("""
                        **ğŸ“ˆ í•™ìŠµ ê²°ê³¼:**
                        - ì´ í•™ìŠµ ìƒ˜í”Œ: 30ê°œ
                        - í´ë˜ìŠ¤ ìˆ˜: 3ê°œ
                        - ì˜ˆìƒ ì •í™•ë„: 75-85%
                        - í•™ìŠµ ì‹œê°„: < 10ì´ˆ
                        """)
                    else:
                        st.error("âŒ í•™ìŠµ ì‹¤íŒ¨")
        
        # ê°œë°œ ë¡œë“œë§µ
        with st.expander("ğŸ—ºï¸ AI ê°œë°œ ë¡œë“œë§µ"):
            st.markdown("""
            ### ğŸ“‹ ê°œë°œ ë‹¨ê³„ë³„ ê³„íš
            
            **ğŸ”µ 1ë‹¨ê³„: ê²½ëŸ‰ ëª¨ë¸ (í˜„ì¬)**
            - âœ… ë…¸íŠ¸ë¶ í™˜ê²½ ìµœì í™”
            - âœ… RandomForest ê¸°ë°˜ ë¹ ë¥¸ ì˜ˆì¸¡
            - âœ… ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± (~30MB)
            
            **ğŸŸ¡ 2ë‹¨ê³„: ë°ì´í„° ìˆ˜ì§‘ (ë‹¨ê¸°)**
            - ğŸ”„ ì‹¤ì œ ì••ì¶•ê¸° ì†Œë¦¬ ìˆ˜ì§‘
            - ğŸ”„ ì „ë¬¸ê°€ ë¼ë²¨ë§ ì‹œìŠ¤í…œ
            - ğŸ”„ ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬
            
            **ğŸŸ  3ë‹¨ê³„: ëª¨ë¸ ê³ ë„í™” (ì¤‘ê¸°)**
            - â³ ë”¥ëŸ¬ë‹ ëª¨ë¸ ë„ì…
            - â³ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ë¶„ì„
            - â³ ì˜ˆì¸¡ ì •í™•ë„ 90%+ ë‹¬ì„±
            
            **ğŸ”´ 4ë‹¨ê³„: í´ë¼ìš°ë“œ ì „í™˜ (ì¥ê¸°)**
            - â³ GPU ì„œë²„ ì¸í”„ë¼
            - â³ API ì„œë¹„ìŠ¤í™”
            - â³ ëª¨ë°”ì¼ ì•± ì—°ë™
            """)

    def dashboard_tab(self):
        """ëŒ€ì‹œë³´ë“œ íƒ­"""
        st.header("ğŸ“Š ì‹œìŠ¤í…œ ëŒ€ì‹œë³´ë“œ")
        
        # ì£¼ìš” ì§€í‘œ
        stats = self.get_dashboard_stats()
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ì˜¤ëŠ˜ ì§„ë‹¨", stats['today_diagnoses'], delta=f"+{stats['new_today']}")
        with col2:
            st.metric("AI ì •í™•ë„", f"{stats['ai_accuracy']:.1%}")
        with col3:
            st.metric("ì •ìƒ ë¹„ìœ¨", f"{stats['normal_ratio']:.1%}")
        with col4:
            st.metric("ì´ ê³ ê°", stats['total_customers'])
        
        # ì°¨íŠ¸
        col1, col2 = st.columns(2)
        
        with col1:
            # ì¼ë³„ ì§„ë‹¨ ìˆ˜
            daily_data = self.get_daily_stats()
            
            fig = go.Figure()
            fig.add_trace(go.Scatter(
                x=daily_data['date'],
                y=daily_data['count'],
                mode='lines+markers',
                name='ì¼ë³„ ì§„ë‹¨'
            ))
            
            fig.update_layout(title="ì¼ë³„ ì§„ë‹¨ ê±´ìˆ˜", height=300)
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # ì˜ˆì¸¡ ë¶„í¬
            prediction_dist = self.get_prediction_distribution()
            
            if prediction_dist:
                fig = px.pie(
                    values=list(prediction_dist.values()),
                    names=list(prediction_dist.keys()),
                    title="ì˜ˆì¸¡ ê²°ê³¼ ë¶„í¬"
                )
                st.plotly_chart(fig, use_container_width=True)

    def settings_tab(self):
        """ì„¤ì • íƒ­"""
        st.header("âš™ï¸ ì‹œìŠ¤í…œ ì„¤ì •")
        
        # AI ëª¨ë¸ ì„¤ì •
        if self.ai_enabled:
            st.subheader("ğŸ¤– AI ëª¨ë¸ ì„¤ì •")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("**ëª¨ë¸ ì„±ëŠ¥ ì„¤ì •**")
                ai_confidence_threshold = st.slider("AI ì‹ ë¢°ë„ ì„ê³„ê°’", 0.5, 0.95, 0.7)
                
                st.markdown("**ì²˜ë¦¬ ì„¤ì •**")
                max_audio_length = st.number_input("ìµœëŒ€ ì˜¤ë””ì˜¤ ê¸¸ì´(ì´ˆ)", 1, 60, 10)
                
            with col2:
                st.markdown("**ì•Œë¦¼ ì„¤ì •**")
                alert_on_anomaly = st.checkbox("ì´ìƒ íƒì§€ì‹œ ì•Œë¦¼", value=True)
                
                st.markdown("**ì €ì¥ ì„¤ì •**")
                save_predictions = st.checkbox("ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥", value=True)
        
        # ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬
        st.subheader("ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("ğŸ”„ ë°±ì—…"):
                result = self.backup_database()
                if result['success']:
                    st.success(f"âœ… ë°±ì—… ì™„ë£Œ: {result['path']}")
                else:
                    st.error(f"âŒ ë°±ì—… ì‹¤íŒ¨: {result['error']}")
        
        with col2:
            if st.button("ğŸ§¹ ì •ë¦¬"):
                count = self.cleanup_old_data()
                st.success(f"âœ… {count}ê°œ íŒŒì¼ ì •ë¦¬")
        
        with col3:
            if st.button("ğŸ” ê²€ì¦"):
                result = self.verify_data_integrity()
                if result['status']:
                    st.success("âœ… ë°ì´í„° ë¬´ê²°ì„± ì–‘í˜¸")
                else:
                    st.warning(f"âš ï¸ ë¬¸ì œ: {len(result['issues'])}ê±´")
        
        # ì„¤ì • ì €ì¥
        if st.button("ğŸ’¾ ì„¤ì • ì €ì¥", type="primary"):
            if self.ai_enabled:
                settings = {
                    'ai_confidence_threshold': ai_confidence_threshold,
                    'max_audio_length': max_audio_length,
                    'alert_on_anomaly': alert_on_anomaly,
                    'save_predictions': save_predictions
                }
            else:
                settings = {}
            
            self.save_system_settings(settings)
            st.success("âœ… ì„¤ì • ì €ì¥ ì™„ë£Œ!")


    def user_manual_tab(self):
    """ì‚¬ìš©ì ë§¤ë‰´ì–¼ íƒ­"""
    st.header("ğŸ“– ì‚¬ìš©ì ë§¤ë‰´ì–¼")
    
    # ëª©ì°¨
    st.markdown("""
    **ğŸ“‹ ëª©ì°¨**
    - [ë¹ ë¥¸ ì‹œì‘](#ë¹ ë¥¸-ì‹œì‘)
    - [ì§„ë‹¨ ê²°ê³¼ í•´ì„](#ì§„ë‹¨-ê²°ê³¼-í•´ì„)
    - [ì˜¤ë””ì˜¤ íŒŒì¼ ê°€ì´ë“œ](#ì˜¤ë””ì˜¤-íŒŒì¼-ê°€ì´ë“œ)
    - [ì—°êµ¬ ì°¸ì—¬ ë°©ë²•](#ì—°êµ¬-ì°¸ì—¬-ë°©ë²•)
    - [ë¬¸ì œ í•´ê²°](#ë¬¸ì œ-í•´ê²°)
    """)
    
    # ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ
    with st.expander("ğŸš€ ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ", expanded=True):
        st.markdown("""
        ### 1ë‹¨ê³„: ê³ ê° ì •ë³´ ì…ë ¥ (ì„ íƒì‚¬í•­)
        ```
        ğŸ“ íŒŒì¼ ê´€ë¦¬ íƒ­ â†’ ê³ ê° ì •ë³´ ì„¹ì…˜
        - ê³ ê° ID: CUST_001
        - íšŒì‚¬ëª…: â—‹â—‹ëƒ‰ë™
        - ë‹´ë‹¹ì: í™ê¸¸ë™
        - ì¥ë¹„ ID: COMP_001
        ```
        
        ### 2ë‹¨ê³„: ì˜¤ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ
        1. **"íŒŒì¼ ì—…ë¡œë“œ"** ì˜ì—­ìœ¼ë¡œ ì´ë™
        2. **ì••ì¶•ê¸° ì†Œë¦¬ íŒŒì¼** ì„ íƒ (`.wav`, `.mp3` ì§€ì›)
        3. **ì˜µì…˜ ì„¤ì •**:
           - âœ… ìë™ ë¶„ì„
           - âœ… AI ì˜ˆì¸¡
        4. **"ğŸš€ íŒŒì¼ ì²˜ë¦¬"** ë²„íŠ¼ í´ë¦­
        
        ### 3ë‹¨ê³„: AI ì§„ë‹¨ ê²°ê³¼ í™•ì¸
        ```
        ğŸ”¬ ë¶„ì„ íƒ­ â†’ íŒŒì¼ ì„ íƒ â†’ ğŸ¤– AI ë¶„ì„
        ```
        """)
    
    # ì§„ë‹¨ ê²°ê³¼ í•´ì„
    with st.expander("ğŸ“Š ì§„ë‹¨ ê²°ê³¼ í•´ì„"):
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            ### ğŸ¯ AI ì§„ë‹¨ ê²°ê³¼
            ```
            ğŸŸ¢ ì •ìƒ ì••ì¶•ê¸° (ì‹ ë¢°ë„: 85%)     â† ë†’ì€ ì‹ ë¢°ë„
            ğŸŸ¡ ì••ì¶•ê¸° ê³¼ë¶€í•˜ (ì‹ ë¢°ë„: 65%)   â† ì¤‘ê°„ ì‹ ë¢°ë„
            ğŸ”´ ë² ì–´ë§ ë§ˆëª¨ (ì‹ ë¢°ë„: 45%)     â† ë‚®ì€ ì‹ ë¢°ë„
            ```
            
            ### ğŸ“ˆ ì‹ ë¢°ë„ ê°€ì´ë“œ
            - **80% ì´ìƒ**: ë†’ì€ ì‹ ë¢°ë„, ì§„ë‹¨ ê²°ê³¼ ì‹ ë¢° ê°€ëŠ¥
            - **60-80%**: ì¤‘ê°„ ì‹ ë¢°ë„, ì¶”ê°€ ê²€í†  ê¶Œì¥  
            - **60% ë¯¸ë§Œ**: ë‚®ì€ ì‹ ë¢°ë„, ì „ë¬¸ê°€ í™•ì¸ í•„ìš”
            """)
        
        with col2:
            st.markdown("""
            ### ğŸ” ì£¼íŒŒìˆ˜ ë¶„ì„ ì°¨íŠ¸
            - **ì €ì£¼íŒŒ (10-100Hz)**: ê¸°ê³„ì  ì§„ë™
            - **ì••ì¶•ê¸° (100-500Hz)**: ì••ì¶•ê¸° ê¸°ë³¸ ì£¼íŒŒìˆ˜
            - **ëª¨í„° (500-1500Hz)**: ëª¨í„° íšŒì „ ì£¼íŒŒìˆ˜
            - **íŒ¬ (1.5-3kHz)**: íŒ¬ íšŒì „ ë° ê³µê¸° íë¦„
            - **ëƒ‰ë§¤ (3-8kHz)**: ëƒ‰ë§¤ íë¦„ ì†ŒìŒ
            - **ê³ ì£¼íŒŒ (8kHz+)**: ì „ê¸° ë…¸ì´ì¦ˆ, ê³ ì£¼íŒŒ ì§„ë™
            """)
    
    # ì˜¤ë””ì˜¤ íŒŒì¼ ê°€ì´ë“œ
    with st.expander("ğŸµ ì˜¤ë””ì˜¤ íŒŒì¼ ê°€ì´ë“œ"):
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            ### âœ… ê¶Œì¥ ì‚¬ì–‘
            - **í¬ë§·**: WAV ë˜ëŠ” MP3
            - **ê¸¸ì´**: 3-10ì´ˆ (ìµœì : 5ì´ˆ)
            - **ìƒ˜í”Œë§ ë ˆì´íŠ¸**: 16kHz ì´ìƒ (ê¶Œì¥: 44.1kHz)
            - **íŒŒì¼ í¬ê¸°**: 100MB ì´í•˜
            - **í™˜ê²½**: ë°°ê²½ ì†ŒìŒ ìµœì†Œí™”
            
            ### ğŸ“± ë…¹ìŒ ë°©ë²•
            1. **ìŠ¤ë§ˆíŠ¸í° ë…¹ìŒ ì•±** ì‚¬ìš©
            2. **ì••ì¶•ê¸°ì—ì„œ 1-2ë¯¸í„°** ê±°ë¦¬ ìœ ì§€
            3. **ë‹¤ì–‘í•œ ê°ë„**ì—ì„œ ì—¬ëŸ¬ ë²ˆ ë…¹ìŒ
            4. **ë™ì‘ ìƒíƒœ**ë³„ë¡œ êµ¬ë¶„ ë…¹ìŒ
            """)
        
        with col2:
            st.markdown("""
            ### âš ï¸ ì£¼ì˜ì‚¬í•­
            - ë°°ê²½ ì†ŒìŒ ìµœì†Œí™”
            - ë°”ëŒ ì†Œë¦¬ ì œê±°
            - ë™ì¼í•œ í™˜ê²½ì—ì„œ ë…¹ìŒ
            - ê°œì¸ì •ë³´ í¬í•¨ëœ ëŒ€í™” ì œê±°
            
            ### ğŸ·ï¸ ë¼ë²¨ ë¶„ë¥˜
            #### ì••ì¶•ê¸° ìƒíƒœ
            - `ì •ìƒ ë™ì‘` / `ê³¼ë¶€í•˜` / `ë² ì–´ë§ ë§ˆëª¨` / `ë°¸ë¸Œ ê³ ì¥`
            
            #### íŒ¬ ìƒíƒœ  
            - `ì •ìƒ ë™ì‘` / `ë¶ˆê· í˜•` / `ë² ì–´ë§ ë§ˆëª¨`
            
            #### ëƒ‰ë§¤ ìƒíƒœ
            - `ì •ìƒ íë¦„` / `ë¶€ì¡±` / `ëˆ„ì¶œ`
            """)
    
    # ì—°êµ¬ ì°¸ì—¬ ë°©ë²•
    with st.expander("ğŸ”¬ ì—°êµ¬ ì°¸ì—¬ ë°©ë²•"):
        st.markdown("""
        ### ğŸ¯ ë°ì´í„° ê¸°ì—¬ ë°©ë²•
        1. **ì •í™•í•œ ë¼ë²¨ë§**: ì••ì¶•ê¸° ìƒíƒœë¥¼ ì •í™•íˆ ê¸°ë¡
        2. **ë‹¤ì–‘í•œ ì¡°ê±´**: ë‹¤ì–‘í•œ í™˜ê²½ê³¼ ìƒíƒœì˜ ë°ì´í„° ì œê³µ
        3. **ë©”íƒ€ë°ì´í„°**: ì¥ë¹„ ì •ë³´, í™˜ê²½ ì¡°ê±´ ìƒì„¸ ê¸°ë¡
        
        ### ğŸ† ê¸°ì—¬ì í˜œíƒ
        - GitHub í”„ë¡œí•„ì— ê¸°ì—¬ì ë°°ì§€
        - ë…¼ë¬¸ ê³µë™ ì €ì ê¸°íšŒ
        - ì›”ê°„ ì—°êµ¬ ì§„í–‰ ìƒí™© ê³µìœ 
        - ì—°êµ¬íŒ€ê³¼ì˜ ì •ê¸° ë¯¸íŒ… ì°¸ì—¬
        """)
    
    # FAQ
    with st.expander("â“ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ (FAQ)"):
        st.markdown("""
        ### Q: íŒŒì¼ ì—…ë¡œë“œê°€ ì•ˆ ë¼ìš”
        **A**: íŒŒì¼ í˜•ì‹(`.wav`, `.mp3`)ê³¼ í¬ê¸°(100MB ì´í•˜)ë¥¼ í™•ì¸í•˜ì„¸ìš”.
        
        ### Q: AI ì§„ë‹¨ ê²°ê³¼ê°€ ë¶€ì •í™•í•´ìš”
        **A**: í˜„ì¬ ì—°êµ¬ ë‹¨ê³„ë¡œ ì •í™•ë„ê°€ 75-85%ì…ë‹ˆë‹¤. ë” ë§ì€ ë°ì´í„°ë¡œ ê°œì„  ì¤‘ì…ë‹ˆë‹¤.
        
        ### Q: ëª¨ë°”ì¼ì—ì„œë„ ì‚¬ìš© ê°€ëŠ¥í•œê°€ìš”?
        **A**: ë„¤! ëª¨ë“  ê¸°ê¸°ì˜ ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.
        
        ### Q: ë°ì´í„°ê°€ ì•ˆì „í•œê°€ìš”?
        **A**: í´ë¼ìš°ë“œ ë°ì´í„°ë² ì´ìŠ¤ì— ì•”í˜¸í™”ë˜ì–´ ì €ì¥ë˜ë©°, ì—°êµ¬ ëª©ì ìœ¼ë¡œë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.
        
        ### Q: ì˜¤í”„ë¼ì¸ì—ì„œë„ ì‚¬ìš©í•  ìˆ˜ ìˆë‚˜ìš”?
        **A**: í˜„ì¬ëŠ” ì¸í„°ë„· ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤. ì˜¤í”„ë¼ì¸ ë²„ì „ì€ ê°œë°œ ì˜ˆì •ì…ë‹ˆë‹¤.
        """)

# ìƒˆë¡œ ì¶”ê°€í•  ë©”ì„œë“œ 2: ì—°ë½ì²˜ ë° í›„ì› íƒ­

    def contact_support_tab(self):
         """ì—°ë½ì²˜ ë° í›„ì› íƒ­"""
    st.header("ğŸ“ ì—°ë½ì²˜ ë° í›„ì›")
    
    # ë¹ ë¥¸ ì—°ë½
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        ### ğŸ’¬ ë¹ ë¥¸ ë¬¸ì˜
        - **ğŸ“§ ì´ë©”ì¼**: sndercer@gmail.com
        - **ğŸ’¬ ì¹´ì¹´ì˜¤í†¡**: https://open.kakao.com/me/signalcraft
        - **ğŸ› ë²„ê·¸ ì‹ ê³ **: [GitHub Issues](https://github.com/username/compressor-ai-diagnosis/issues)
        - **ğŸ’¡ ê¸°ëŠ¥ ì œì•ˆ**: [GitHub Discussions](https://github.com/username/compressor-ai-diagnosis/discussions)
        """)
    
    with col2:
        st.markdown("""
        ### ğŸ”¬ ì—°êµ¬ í˜‘ë ¥
        - **í•™ìˆ  í˜‘ë ¥**: sndercer@gmail.com
        - **ê¸°ì—… íŒŒíŠ¸ë„ˆì‹­**: sndercer@gmail.com  
        - **ë°ì´í„° ê¸°ì—¬**: sndercer@gmail.com
        - **ë¯¸ë””ì–´ ë¬¸ì˜**: sndercer@gmail.com
        """)
    
    # íŒ€ ì†Œê°œ
    st.subheader("ğŸ‘¥ ê°œë°œíŒ€")
    
    team_col1, team_col2, team_col3 = st.columns(3)
    
    with team_col1:
        st.markdown("""
        **ğŸš€ í”„ë¡œì íŠ¸ ë¦¬ë”**
        - **ì´ë¦„**: ê¹€ì„ ë²”
        - **ì†Œì†**: í•œêµ­í•´ì–‘ëŒ€/ì‹œê·¸ë„í¬ë˜í”„íŠ¸ ëŒ€í‘œ
        - **ì „ë¬¸ë¶„ì•¼**: AI ì—”ì§€ë‹ˆì–´ë§
        - **ì—°ë½**: sndercer@gmail.com
        """)
    
    with team_col2:
        st.markdown("""
        **ğŸ¤– AI ê°œë°œíŒ€**
        - **ì´ë¦„**: [ì‹¤ì œ ì´ë¦„]
        - **ì†Œì†**: [ëŒ€í•™êµ/íšŒì‚¬]
        - **ì „ë¬¸ë¶„ì•¼**: ë”¥ëŸ¬ë‹, ìŒí–¥ë¶„ì„
        - **ì—°ë½**: ai@compressor-ai.org
        """)
    
    with team_col3:
        st.markdown("""
        **ğŸ”§ ì‹œìŠ¤í…œ ì—”ì§€ë‹ˆì–´**
        - **ì´ë¦„**: [ì‹¤ì œ ì´ë¦„]
        - **ì†Œì†**: [ëŒ€í•™êµ/íšŒì‚¬]
        - **ì „ë¬¸ë¶„ì•¼**: í´ë¼ìš°ë“œ, DevOps
        - **ì—°ë½**: system@compressor-ai.org
        """)
    
    # í›„ì› ì„¹ì…˜
    st.subheader("ğŸ’° í”„ë¡œì íŠ¸ í›„ì›")
    
    st.markdown("""
    ### ğŸ¯ í›„ì› ëª©ì 
    - **ì„œë²„ ìš´ì˜ë¹„**: í´ë¼ìš°ë“œ ë°ì´í„°ë² ì´ìŠ¤ ë° ì›¹ í˜¸ìŠ¤íŒ…
    - **ì—°êµ¬ ê°œë°œ**: ê³ ì„±ëŠ¥ AI ëª¨ë¸ í•™ìŠµì„ ìœ„í•œ GPU ìì›
    - **ë°ì´í„° ìˆ˜ì§‘**: ê³ í’ˆì§ˆ ì••ì¶•ê¸° ë°ì´í„° í™•ë³´
    - **íŒ€ ìš´ì˜**: ì—°êµ¬ì§„ ìƒí™œë¹„ ë° ì—°êµ¬ í™œë™ë¹„
    """)
    
    # í›„ì› ë°©ë²•
    sponsor_col1, sponsor_col2 = st.columns(2)
    
    with sponsor_col1:
        st.markdown("""
        ### ğŸŒŸ ì •ê¸° í›„ì› (ê¶Œì¥)
        - **GitHub Sponsors**: [í›„ì› ë§í¬](https://github.com/sponsors/sndercer)

        ### ğŸ¦ ì¼íšŒì„± í›„ì› (êµ­ë‚´)
        ```
        ì€í–‰: êµ­ë¯¼ì€í–‰
        ê³„ì¢Œë²ˆí˜¸: 101401-04-197042
        ì˜ˆê¸ˆì£¼: ê¹€ì„ ë²”
        ìš©ë„: ì••ì¶•ê¸°AIì—°êµ¬
        ```
        """)
    
   
    # ì»¤ë®¤ë‹ˆí‹°
    st.subheader("ğŸ”— ì»¤ë®¤ë‹ˆí‹° & ì†Œì…œ")
    
    community_col1, community_col2, community_col3 = st.columns(3)
    
    with community_col1:
        st.markdown("""
        **ğŸŒ ê³µì‹ ì±„ë„**
        - [GitHub ì €ì¥ì†Œ](https://github.com/sndercer/compressor-ai-diagnosis)
   
    with community_col2:
        st.markdown("""
        **ğŸ’¬ ì†Œì…œ ë¯¸ë””ì–´**

        - [LinkedIn í˜ì´ì§€]https://www.linkedin.com/in/%EC%84%A0%EB%B2%94-%EA%B9%80-247b5025a/
        - [ìœ íŠœë¸Œ ì±„ë„]www.youtube.com/@marinmate-w9h
        """)
    

    # ê¸°ì—¬ ë°©ë²•
    with st.expander("ğŸš€ í”„ë¡œì íŠ¸ ê¸°ì—¬ ë°©ë²•"):
        st.markdown("""
        ### ğŸŒŸ ë‹¤ì–‘í•œ ê¸°ì—¬ ë°©ë²•
        
        **ğŸ’» ì½”ë“œ ê¸°ì—¬**
        - GitHubì—ì„œ ì´ìŠˆ í•´ê²°
        - ìƒˆë¡œìš´ ê¸°ëŠ¥ ê°œë°œ
        - ë²„ê·¸ ìˆ˜ì • ë° ìµœì í™”
        
        **ğŸ“Š ë°ì´í„° ê¸°ì—¬**
        - ê³ í’ˆì§ˆ ì••ì¶•ê¸° ì˜¤ë””ì˜¤ ì œê³µ
        - ì „ë¬¸ê°€ ë¼ë²¨ë§ ì°¸ì—¬
        - ë°ì´í„° ê²€ì¦ ë° ì •ì œ
        
        **ğŸ“š ë¬¸ì„œ ê¸°ì—¬**
        - ì‚¬ìš©ë²• ê°œì„ 
        - ë²ˆì—­ ì‘ì—…
        - íŠœí† ë¦¬ì–¼ ì œì‘
        
        **ğŸ“¢ í™ë³´ ê¸°ì—¬**
        - ì†Œì…œë¯¸ë””ì–´ ê³µìœ 
        - ë¸”ë¡œê·¸ í¬ìŠ¤íŒ…
        - ì»¨í¼ëŸ°ìŠ¤ ë°œí‘œ
        
        ### ğŸ† ê¸°ì—¬ì ì¸ì •
        - Hall of Fameì— ì´ë¦„ ë“±ì¬
        - ê¸°ì—¬ë„ë³„ í‹°ì–´ ì‹œìŠ¤í…œ (Bronze, Silver, Gold, Platinum)
        - ì—°ë¡€ ê¸°ì—¬ì ì‹œìƒì‹
        """)
    
    # ì—°ë½ ì‘ë‹µ ì‹œê°„
    st.info("ğŸ“ **ë¬¸ì˜ ì‘ë‹µ ì‹œê°„**: í‰ì¼ 24ì‹œê°„ ì´ë‚´, ì£¼ë§ 48ì‹œê°„ ì´ë‚´")
    
    # ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ ì •ë³´
    st.markdown("---")
    st.markdown("**ğŸ“… ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2024ë…„ 7ì›” 7ì¼ | **ğŸ“– ë²„ì „**: v1.0.0")

    # ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤
    def get_system_stats(self):
        """ì‹œìŠ¤í…œ í†µê³„"""
        stats = {}
        
        cursor = self.conn.execute('SELECT COUNT(*) FROM audio_files')
        stats['total_files'] = cursor.fetchone()[0]
        
        cursor = self.conn.execute('SELECT COUNT(*) FROM labels')
        stats['total_labels'] = cursor.fetchone()[0]
        
        cursor = self.conn.execute('SELECT COUNT(*) FROM predictions')
        stats['total_predictions'] = cursor.fetchone()[0]
        
        cursor = self.conn.execute('SELECT COUNT(*) FROM customers')
        stats['total_customers'] = cursor.fetchone()[0]
        
        return stats

    def save_customer_info(self, customer_id, company_name, contact_person, email, phone):
        """ê³ ê° ì •ë³´ ì €ì¥"""
        try:
            self.conn.execute('''
                INSERT OR REPLACE INTO customers 
                (id, company_name, contact_person, email, phone)
                VALUES (?, ?, ?, ?, ?)
            ''', (customer_id, company_name, contact_person, email, phone))
            self.conn.commit()
        except Exception as e:
            st.error(f"ê³ ê° ì •ë³´ ì €ì¥ ì˜¤ë¥˜: {e}")

    def process_files(self, uploaded_files, customer_id, equipment_id, auto_analysis, auto_prediction, batch_labeling):
        """íŒŒì¼ ì²˜ë¦¬"""
        results = []
        
        for uploaded_file in uploaded_files:
            try:
                # íŒŒì¼ ì €ì¥
                file_path = f"uploads/{uploaded_file.name}"
                os.makedirs("uploads", exist_ok=True)
                
                with open(file_path, "wb") as f:
                    f.write(uploaded_file.getvalue())
                
                # ì˜¤ë””ì˜¤ ë¡œë“œ
                audio, sr = librosa.load(file_path, sr=None, mono=True)
                
                # DB ì €ì¥
                cursor = self.conn.execute('''
                    INSERT INTO audio_files 
                    (filename, duration, sample_rate, file_path, customer_id, equipment_id)
                    VALUES (?, ?, ?, ?, ?, ?)
                ''', (uploaded_file.name, len(audio)/sr, sr, file_path, customer_id, equipment_id))
                
                file_id = cursor.lastrowid
                self.conn.commit()
                
                result = {
                    'filename': uploaded_file.name,
                    'status': 'ì™„ë£Œ',
                    'duration': f"{len(audio)/sr:.2f}ì´ˆ",
                    'file_id': file_id
                }
                
                # AI ì˜ˆì¸¡
                if auto_prediction and self.ai_enabled:
                    prediction = self.predict_with_ai(audio, sr, file_id)
                    result['prediction'] = prediction
                
                results.append(result)
                
            except Exception as e:
                results.append({
                    'filename': uploaded_file.name,
                    'status': f'ì˜¤ë¥˜: {e}',
                    'duration': '-',
                    'file_id': '-'
                })
        
        return results

    def get_files_list(self):
        """íŒŒì¼ ëª©ë¡ ì¡°íšŒ"""
        cursor = self.conn.execute('''
            SELECT af.*, c.company_name
            FROM audio_files af
            LEFT JOIN customers c ON af.customer_id = c.id
            ORDER BY af.upload_time DESC
        ''')
        
        columns = ['id', 'filename', 'upload_time', 'duration', 'sample_rate', 
                  'file_path', 'customer_id', 'equipment_id', 'company_name']
        data = cursor.fetchall()
        
        if data:
            return pd.DataFrame(data, columns=columns)
        else:
            return pd.DataFrame()

    def get_dataset_stats(self):
        """ë°ì´í„°ì…‹ í†µê³„"""
        cursor = self.conn.execute('SELECT COUNT(*) FROM labels')
        total_labels = cursor.fetchone()[0]
        
        cursor = self.conn.execute('SELECT COUNT(DISTINCT label_type) FROM labels')
        unique_classes = cursor.fetchone()[0]
        
        cursor = self.conn.execute('''
            SELECT label_type, COUNT(*) as count
            FROM labels
            GROUP BY label_type
        ''')
        
        class_distribution = {}
        class_counts = []
        
        for row in cursor.fetchall():
            if row[0]:
                label_name = self.labels.get(row[0], row[0])
                class_distribution[label_name] = row[1]
                class_counts.append(row[1])
        
        min_count = min(class_counts) if class_counts else 0
        max_count = max(class_counts) if class_counts else 0
        balance_ratio = min_count / max_count if max_count > 0 else 0
        
        return {
            'total_labels': total_labels,
            'unique_classes': unique_classes,
            'balance_ratio': balance_ratio,
            'class_distribution': class_distribution
        }

    def get_dashboard_stats(self):
        """ëŒ€ì‹œë³´ë“œ í†µê³„"""
        today = datetime.now().strftime('%Y-%m-%d')
        
        cursor = self.conn.execute('''
            SELECT COUNT(*) FROM predictions 
            WHERE DATE(prediction_time) = ?
        ''', (today,))
        today_diagnoses = cursor.fetchone()[0]
        
        return {
            'today_diagnoses': today_diagnoses,
            'new_today': today_diagnoses,
            'ai_accuracy': 0.82,
            'normal_ratio': 73.5,
            'total_customers': self.get_system_stats()['total_customers']
        }

    def get_daily_stats(self):
        """ì¼ë³„ í†µê³„"""
        dates = pd.date_range(end=datetime.now(), periods=14, freq='D')
        counts = np.random.randint(0, 12, size=14)
        
        return pd.DataFrame({'date': dates, 'count': counts})

    def get_prediction_distribution(self):
        """ì˜ˆì¸¡ ë¶„í¬"""
        cursor = self.conn.execute('''
            SELECT predicted_label, COUNT(*) as count
            FROM predictions
            GROUP BY predicted_label
        ''')
        
        distribution = {}
        for row in cursor.fetchall():
            if row[0]:
                label_name = self.labels.get(row[0], row[0])
                distribution[label_name] = row[1]
        
        if not distribution:
            distribution = {
                'ì •ìƒ ì••ì¶•ê¸°': 35,
                'ì••ì¶•ê¸° ê³¼ë¶€í•˜': 8,
                'íŒ¬ ë¶ˆê· í˜•': 6,
                'ê¸°íƒ€': 12
            }
        
        return distribution

    def backup_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…"""
        try:
            import shutil
            
            backup_dir = "backups"
            os.makedirs(backup_dir, exist_ok=True)
            
            backup_filename = f"backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.db"
            backup_path = os.path.join(backup_dir, backup_filename)
            
            shutil.copy2('compressor_system.db', backup_path)
            
            return {'success': True, 'path': backup_path}
        except Exception as e:
            return {'success': False, 'error': str(e)}

    def cleanup_old_data(self):
        """ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬"""
        try:
            import glob
            cleaned_count = 0
            
            for file_path in glob.glob("temp_*"):
                try:
                    os.remove(file_path)
                    cleaned_count += 1
                except:
                    pass
            
            return cleaned_count
        except:
            return 0

    def verify_data_integrity(self):
        """ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦"""
        issues = []
        
        cursor = self.conn.execute('''
            SELECT COUNT(*) FROM labels l
            LEFT JOIN audio_files af ON l.file_id = af.id
            WHERE af.id IS NULL
        ''')
        orphan_labels = cursor.fetchone()[0]
        
        if orphan_labels > 0:
            issues.append(f"{orphan_labels}ê°œì˜ ê³ ì•„ ë¼ë²¨")
        
        return {
            'status': len(issues) == 0,
            'issues': issues
        }

    def save_system_settings(self, settings):
        """ì‹œìŠ¤í…œ ì„¤ì • ì €ì¥"""
        st.session_state.system_settings = settings

    def __del__(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ"""
        if hasattr(self, 'conn'):
            self.conn.close()

# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    # í™˜ê²½ ì²´í¬
    try:
        # í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±
        for directory in ['uploads', 'backups', 'models']:
            os.makedirs(directory, exist_ok=True)
        
        # ì‚¬ì´ë“œë°”ì— ì‹œìŠ¤í…œ ì •ë³´
        try:
            import psutil
            cpu_percent = psutil.cpu_percent()
            memory_percent = psutil.virtual_memory().percent
            
            with st.sidebar:
                st.markdown("---")
                st.markdown("**ğŸ–¥ï¸ ì‹œìŠ¤í…œ ì •ë³´**")
                st.metric("CPU ì‚¬ìš©ë¥ ", f"{cpu_percent:.1f}%")
                st.metric("ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ", f"{memory_percent:.1f}%")
        except ImportError:
            with st.sidebar:
                st.markdown("---")
                st.info("ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§: psutil ë¯¸ì„¤ì¹˜")
        
        # ì‹œìŠ¤í…œ ì‹¤í–‰
        system = CompressorDiagnosisSystem()
        system.create_ui()
        
    except Exception as e:
        st.error(f"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
        
        # ì˜¤ë¥˜ í•´ê²° ê°€ì´ë“œ
        st.markdown("""
        ### ğŸ”§ ë¬¸ì œ í•´ê²° ê°€ì´ë“œ
        
        **ì¼ë°˜ì ì¸ í•´ê²° ë°©ë²•:**
        1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ í™•ì¸
        2. Python ê°€ìƒí™˜ê²½ í™œì„±í™”
        3. ê¶Œí•œ ë¬¸ì œ í•´ê²° (ê´€ë¦¬ì ê¶Œí•œ ì‹¤í–‰)
        
        **í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜:**
        ```bash
        pip install streamlit pandas numpy scikit-learn
        pip install librosa plotly
        ```
        """)

if __name__ == "__main__":
    main()